{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20220420_Scrapy.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOsCMvqjuGixHZ17/HMICfd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["scrapy startproject p1\n","- p1 이라는 이름을 가진 scrapy 프로젝트 생성\n","\n","scrapy genspider name 'site address'\n","- 특정 사이트에 대한 genspider을 name 이름으로 생성 (시작 site)\n","\n","scrapy shell 'site address'\n","- 특정 사이트의 shell을 생성\n","- Xpath를 알기 위함\n","\n","response.xpath( )\n","- shell내에서 답을 얻기 위한 요청\n","\n","response.xpath( ).getall()\n","- 특정 정보 저장 (list로 저장)\n","\n","response.xpath( ).get()\n","- 특정 정보 단일 저장\n","\n","response.urljoin()\n","- url합치기 (다음 페이지로 넘어가기 위한 기능)\n","\n","scrapy crawl ~~\n","- ~~.py 코드를 이용하여 crawling 시작\n","\n","(--nolog: log 생략)\n","\n","response.follow(next_link, callback = self.parse)\n","- 다음 page로 이동\n"],"metadata":{"id":"4IX2YLPZtYQD"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"kbhZjKJmbSQz","executionInfo":{"status":"ok","timestamp":1650454450291,"user_tz":-540,"elapsed":716,"user":{"displayName":"설진우","userId":"17367759130491423653"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n"]},{"cell_type":"code","source":["import scrapy\n","import pandas as pd\n","\n","class QuotesSpider(scrapy.Spider):\n","    name = 'quotes'\n","    allowed_domains = ['quotes.toscrape.com']\n","    start_urls = ['http://quotes.toscrape.com/']\n","\n","    def parse(self, response):\n","        x = response.xpath('//span[@class = \"text\"]/text()').getall()\n","        y = response.xpath('//small[@class = \"author\"]/text()').getall()\n","#         pd_data = pd.DataFrame(x)\n","#         pd_data['author'] = y\n","#         pd_data.columns = ['quotes', 'author']\n","#         pd_data.to_csv('pd_data.csv')\n","        yield { 'quote':x, 'author':y}\n","        next_link = response.xpath('//a[contains(text(), \"Next\")]/@href').get()\n","        if next_link is not None:\n","            yield response.follow(next_link, callback = self.parse)\n"],"metadata":{"id":"eJNRLt52wCSv"},"execution_count":null,"outputs":[]}]}